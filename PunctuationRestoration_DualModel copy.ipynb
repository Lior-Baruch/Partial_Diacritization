{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "from torch.nn import Transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score , roc_auc_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import random\n",
    "import math\n",
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define seed for reproducibility\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nikud unicode range (https://en.wikipedia.org/wiki/Unicode_and_HTML_for_the_Hebrew_alphabet)\n",
    "\n",
    "\n",
    "#dictionary of nikud to name\n",
    "nikud_dict = { 'ְ' : 'Sheva', 'ֱ' : 'Hataf Segol', 'ֲ' : 'Hataf Patah', 'ֳ' : 'Hataf Qamats', 'ִ' : 'Hiriq', 'ֵ' : 'Tseri', 'ֶ' : 'Segol', 'ַ' : 'Patah', 'ָ' : 'Qamats', 'ֹ' : 'Holam', 'ֻ' : 'Qubuts', 'ּ' : 'Dagesh', 'ֽ' : 'Siluk', '־' : 'Maqaf', 'ֿ' : 'Rafe', 'ׁ' : 'Shin Dot', 'ׂ' : 'Sin Dot', 'ׄ' : 'Upper Dot', 'ׅ' : 'Lower Dot', 'ׇ' : 'Point Meteg', 'װ' : 'Yiddish Double Vav', 'ױ' : 'Yiddish Vav Yod', 'ײ' : 'Yiddish Double Yod', '׳' : 'Geresh', '״' : 'Gershayim' }\n",
    "# make inverse dictionary\n",
    "nikud_dict_inv = {v: k for k, v in nikud_dict.items()}\n",
    "\n",
    "# Read a txt file from the author files dictionary\n",
    "def read_txt_file(file_path):\n",
    "    \"\"\"\n",
    "    This function reads a txt file and returns the text as a string.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "def remove_nikud(string):\n",
    "    \"\"\"Removes the nikud from the given string.\"\"\"\n",
    "    nikud = re.compile(r'[\\u0591-\\u05C7]')\n",
    "    return nikud.sub(\"\", string)\n",
    "\n",
    "def get_nikud(word):\n",
    "    \"\"\"Returns the nikud from the given word.\"\"\"\n",
    "    nikud = re.compile(r'[\\u0591-\\u05C7]')\n",
    "    current_nikud = ''\n",
    "    nikud_arr = []\n",
    "    for i in range(len(word)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if nikud.match(word[i]):\n",
    "            current_nikud += word[i]\n",
    "        else:\n",
    "            nikud_arr.append(current_nikud)\n",
    "            current_nikud = ''\n",
    "    nikud_arr.append(current_nikud)\n",
    "    return nikud_arr\n",
    "\n",
    "def add_nikud(word, nikud):\n",
    "    \"\"\"Adds the nikud to the given word.\"\"\"\n",
    "    new_word = ''\n",
    "    for i in range(len(word)):\n",
    "        new_word += word[i] + nikud[i]\n",
    "    return new_word\n",
    "\n",
    "def add_nikud_to_text(text, nikud):\n",
    "    \"\"\"Adds the nikud to the given text.\"\"\"\n",
    "    new_text = ''\n",
    "    for word in text.split(' '):\n",
    "        new_text += add_nikud(word, nikud) + ' '\n",
    "    return new_text\n",
    "\n",
    "def remove_first_char_if_nikud(word):\n",
    "    \"\"\"Removes the first char of the word if it is nikud.\"\"\"\n",
    "    nikud = re.compile(r'[\\u0591-\\u05C7]')\n",
    "    if nikud.match(word[0]):\n",
    "        return word[1:]\n",
    "    return word\n",
    "\n",
    "def get_words_indices_from_text(text):\n",
    "    \"\"\"Returns the indices of the words in the given text.\"\"\"\n",
    "    text_words = text.split()\n",
    "    text_words_lengths = list(map(len, text_words))\n",
    "    text_words_indices = [(sum(text_words_lengths[:i]), sum(text_words_lengths[:i+1])-1) for i in range(len(text_words_lengths))]\n",
    "    return text_words_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data from the csv and remove sentences with more than 100 chars (without spaces) and save as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### read the json short data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 6)\n"
     ]
    }
   ],
   "source": [
    "# read the json file\n",
    "data_df = pd.read_json('data/full_data_without_puncts.json', orient='records', lines=True, nrows=55000)\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 6)\n"
     ]
    }
   ],
   "source": [
    "# DELETE this block, only for debugging make the data smaller (randomly select 5000 rows)\n",
    "data_df = data_df.sample(n=5000, random_state=1)\n",
    "print(data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define dictionary label_to_id and id_to_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 86217.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<no_nikud>': 0, 'ְ': 1, 'ִ': 2, 'ֵ': 3, 'ֶ': 4, 'ֹ': 5, 'ֽ': 6, 'ָ': 7, 'ֲ': 8, 'ַ': 9, 'ֻ': 10, 'ֱ': 11, 'ׇ': 12, 'ֳ': 13, 'ַָ': 14, 'ִַ': 15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "label_to_id = {'<no_nikud>': 0}\n",
    "id_to_label = {0: '<no_nikud>'}\n",
    "for label_list in tqdm(data_df['nikud']):\n",
    "    # flatten the list\n",
    "    label_list = [item for sublist in label_list for item in sublist]\n",
    "    for label in label_list:\n",
    "        if len(label) == 0:\n",
    "            label = \"<no_nikud>\"\n",
    "        if label not in label_to_id:\n",
    "            label_to_id[label] = len(label_to_id)\n",
    "            id_to_label[len(id_to_label)] = label\n",
    "\n",
    "print(label_to_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count labels for label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 73415.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ְ': 25929, 'ִ': 16984, 'ֵ': 10315, '<no_nikud>': 91941, 'ֶ': 8265, 'ֹ': 9664, 'ֽ': 5095, 'ָ': 23296, 'ֲ': 2770, 'ַ': 18470, 'ֻ': 1059, 'ֱ': 353, 'ׇ': 490, 'ֳ': 49, 'ַָ': 1, 'ִַ': 1}\n",
      "[('<no_nikud>', 91941), ('ְ', 25929), ('ָ', 23296), ('ַ', 18470), ('ִ', 16984), ('ֵ', 10315), ('ֹ', 9664), ('ֶ', 8265), ('ֽ', 5095), ('ֲ', 2770), ('ֻ', 1059), ('ׇ', 490), ('ֱ', 353), ('ֳ', 49), ('ַָ', 1), ('ִַ', 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<no_nikud>': 0.02152641878669276, 'ְ': 0.06523157208088715, 'ִ': 0.06523157208088715, 'ֵ': 0.06523157208088715, 'ֶ': 0.06523157208088715, 'ֹ': 0.06523157208088715, 'ֽ': 0.06523157208088715, 'ָ': 0.06523157208088715, 'ֲ': 0.06523157208088715, 'ַ': 0.06523157208088715, 'ֻ': 0.06523157208088715, 'ֱ': 0.06523157208088715, 'ׇ': 0.06523157208088715, 'ֳ': 0.06523157208088715, 'ַָ': 0.06523157208088715, 'ִַ': 0.06523157208088715}\n"
     ]
    }
   ],
   "source": [
    "# Count the number of each label\n",
    "label_count = {}\n",
    "for label_list in tqdm(data_df['nikud']):\n",
    "    # Flatten the list\n",
    "    label_list = [item for sublist in label_list for item in sublist]\n",
    "    for label in label_list:\n",
    "        if len(label) == 0:\n",
    "            label = \"<no_nikud>\"\n",
    "        if label not in label_count:\n",
    "            label_count[label] = 0\n",
    "        label_count[label] += 1\n",
    "\n",
    "print(label_count)\n",
    "\n",
    "# Plot counts of each label (sorted)\n",
    "sorted_labels = sorted(label_count.items(), key=lambda x: x[1], reverse=True)\n",
    "print(sorted_labels)\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Label Counts')\n",
    "plt.bar([x[0] for x in sorted_labels], [x[1] for x in sorted_labels])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def set_no_nikud_weight(weight=0.33):\n",
    "    label_weights = {}\n",
    "    for label in label_count:\n",
    "        if label == \"<no_nikud>\":\n",
    "            label_weights[label] = weight\n",
    "        else:\n",
    "            label_weights[label] = 1\n",
    "    sum_weights = sum(label_weights.values())\n",
    "    for label in label_weights:\n",
    "        label_weights[label] /= sum_weights\n",
    "    # sort labels by label_to_id\n",
    "    label_weights = {k: v for k, v in sorted(label_weights.items(), key=lambda item: label_to_id[item[0]])}\n",
    "    return label_weights\n",
    "        \n",
    "label_weights = set_no_nikud_weight()\n",
    "print(label_weights)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### download tokenizer and model\n",
    "(alephbert-base, with vocab of words with len <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'C:\\\\Users\\\\baruc\\\\PycharmProjects\\\\pythonProject\\\\Punctuation_Restoration\\\\AlephBERT-main\\\\AlephBERT-main\\\\models\\\\alephbert-base'\n",
    "alephbert_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "alephbert_model = AutoModelForMaskedLM.from_pretrained(\"onlplab/alephbert-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create DataSet class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length:  5000\n",
      "attention mask:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "input_ids:  tensor([   2,  181, 1016, 1034, 1016,  188, 1006, 1008,  190, 1007, 1009,  183,\n",
      "        1039, 1014,  179,  177, 1033, 1010, 1014, 1064,  179, 1008, 1009,  179,\n",
      "        1047, 1033,  180, 1010, 1008,  187, 1005, 1010,  183, 1075, 1013, 1016,\n",
      "         187, 1005, 1007,  183, 1075, 1013, 1016,  176, 1008, 1049,  176, 1039,\n",
      "        1012,  183, 1010, 1044, 1033,  181, 1009, 1033,  188, 1010,  188, 1007,\n",
      "        1013, 1014,  177, 1038, 1034, 1012,    3,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0])\n",
      "nikud:  tensor([ 0,  1,  2,  3,  0,  1,  2,  0,  0,  0,  0,  4,  4,  0,  0,  1,  5,  6,\n",
      "         4,  1,  0,  0,  0,  0,  0,  0,  7,  3,  0,  1,  0,  5,  8,  7,  7,  0,\n",
      "         0,  0,  0,  8,  7,  7,  0,  3,  0,  0,  7,  7,  0,  0,  5,  3,  0,  1,\n",
      "         5,  0,  0,  5,  1,  9,  3,  0,  1,  2,  7,  0,  0, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16])\n",
      "attention mask:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "input_ids:  tensor([   2,  181, 1066, 1049,  176, 1012,  199, 1008, 1039, 1007,  176, 1007,\n",
      "        1016,  180, 1008, 1011, 1016,  190, 1013, 1010, 1039, 1007, 1011,  181,\n",
      "        1039, 1033, 1008,  179, 1047, 1033,  192, 1033, 1005, 1049,  177, 1005,\n",
      "        1013, 1010, 1012,  179, 1009, 1033,  176, 1011, 1038, 1075, 1013,  176,\n",
      "        1008, 1046, 1010, 1014, 1033,  176, 1010,  180, 1008, 1011, 1008, 1014,\n",
      "        1033,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0])\n",
      "nikud:  tensor([ 0,  1,  3,  0,  2,  0,  2,  6,  3,  0,  2,  7,  0,  7,  1,  7,  0,  1,\n",
      "        10,  6,  4,  4,  0,  9,  9,  0,  0,  0,  0,  0,  4, 11,  7,  0,  1,  7,\n",
      "         0,  5,  0,  1,  7,  0,  2,  9,  1,  9,  0,  2,  6,  0,  0,  7,  0,  0,\n",
      "         5,  4,  6,  3,  0,  7,  0,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16])\n",
      "attention mask:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "input_ids:  tensor([   2,  181, 1005, 1007, 1034, 1008,  176, 1005, 1014,  199, 1014, 1033,\n",
      "         177, 1013, 1014, 1037,  185, 1007, 1014, 1033, 1009,  177, 1075, 1005,\n",
      "        1049,  201, 1007, 1009, 1010, 1012,  177, 1008, 1007, 1014, 1033, 1009,\n",
      "           3,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0])\n",
      "nikud:  tensor([ 0,  0,  1,  9,  3,  0,  7,  9,  0,  1,  7,  0,  1,  4,  4,  0,  2,  1,\n",
      "         7,  3,  0,  2,  1,  9,  0,  4,  7,  0,  5,  0,  1,  2,  1,  7,  3,  0,\n",
      "         0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16])\n",
      "attention mask:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "input_ids:  tensor([   2,  190, 1005,  183, 1008, 1008, 1037,  187, 1014, 1011,  194, 1009,\n",
      "         177, 1008, 1033, 1011, 1010,  188, 1005, 1013, 1039, 1007,    3,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0])\n",
      "nikud:  tensor([ 0,  0,  0,  9,  7,  6,  0,  7,  3,  0,  9,  0,  2,  0,  7,  0,  5,  9,\n",
      "         2,  1,  7,  0,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16])\n",
      "attention mask:  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0])\n",
      "input_ids:  tensor([   2,  190, 1066, 1009,  180, 1009, 1008, 1049,  184, 1047, 1005, 1008,\n",
      "         192, 1014, 1033, 1016,  177, 1014, 1010, 1014,  201, 1005, 1010, 1011,\n",
      "        1014,  188, 1005, 1010, 1038, 1013, 1010,  180, 1013,  176, 1037, 1014,\n",
      "        1016, 1012,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0])\n",
      "nikud:  tensor([ 0,  2, 12,  0,  7,  3,  0,  0,  9,  1,  3,  0,  2,  1,  4,  0,  7,  0,\n",
      "         0,  0,  4, 10,  6,  7,  0,  1,  0,  5,  8,  0,  5,  0,  0,  9,  1,  7,\n",
      "         7,  0,  0, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# create pytorch dataset class for punctuation restoration (returns input(text) and target(nikud))\n",
    "\n",
    "class PunctuationRestorationDataset(Dataset):\n",
    "    def __init__(self, data_df, tokenizer, label_to_id, max_len):\n",
    "        self.data = data_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.label_to_id = label_to_id \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index): # TODO: need to make sure not to look at fraction of words\n",
    "        text = self.data.iloc[index]['text_without_nikud']\n",
    "        nikud = self.data.iloc[index]['nikud']  # list of lists of nikud\n",
    "\n",
    "        # flatten nikud list\n",
    "        nikud = [item for sublist in nikud for item in sublist]\n",
    "        # replace empty strings with <no_nikud> token\n",
    "        nikud = [label if label != \"\" else \"<no_nikud>\" for label in nikud]\n",
    "        # replace labels with ids\n",
    "        nikud = [self.label_to_id[label] for label in nikud]\n",
    "\n",
    "        # check if nikud length is the same as text without spaces length\n",
    "        if len(text.replace(\" \", \"\")) != len(nikud):\n",
    "            print(\"text without spaces length: \", len(text.replace(\" \", \"\")))\n",
    "            print(\"nikud length: \", len(nikud))\n",
    "        \n",
    "        # get word indices after tokenization\n",
    "        word_indices = get_words_indices_from_text(text)\n",
    "        # pad word_indices to be the same length as input_ids\n",
    "        word_indices = word_indices + [(-1, -1)] * (self.max_len - len(word_indices))\n",
    "        # convert word_indices to tensor\n",
    "        word_indices = torch.tensor(word_indices, dtype=torch.long)\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # pad nikud to be the same length as input_ids\n",
    "        nikud = [0] + nikud + [0]\n",
    "        nikud = nikud + [len(label_to_id)] * (encoding['input_ids'].shape[1] - len(nikud))\n",
    "        # convert to tensor\n",
    "        nikud = torch.tensor(nikud, dtype=torch.long)\n",
    "        \n",
    "        return {\n",
    "            'text': text,\n",
    "            'nikud': nikud,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'word_indices': word_indices\n",
    "        }\n",
    "\n",
    "\n",
    "# create pytorch dataset class for punctuation restoration (returns input(text) and target(nikud))\n",
    "dataset = PunctuationRestorationDataset(data_df, alephbert_tokenizer, label_to_id, 102)\n",
    "print(\"dataset length: \", len(dataset))\n",
    "\n",
    "# iterate over dataset\n",
    "for i in range(5):\n",
    "    sample = dataset[i]\n",
    "    input_ids = sample['input_ids']\n",
    "    attention_mask = sample['attention_mask']\n",
    "    nikud = sample['nikud']\n",
    "    # check that attention mask has 1s where input_ids does not have padding\n",
    "    print(\"attention mask: \", attention_mask)\n",
    "    print(\"input_ids: \", input_ids)\n",
    "    print(\"nikud: \", nikud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split to train,val and test datasets and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to train, val and test\n",
    "train_size = int(0.9 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# create dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full-Sentence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, dropout=0.1):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, char_embeddings):\n",
    "        return self.dropout(char_embeddings + self.pe[:char_embeddings.size(0), :])\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=512, nhead=8, num_encoder_layers=6, num_decoder_layers=6, dim_feedforward=2048, max_seq_length=102):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.transformer = nn.Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, batch_first=True)\n",
    "        self.output_layer = nn.Linear(d_model, len(label_to_id))\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_seq_length)\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "        # get transformers d_model\n",
    "        d_model = self.transformer.d_model\n",
    "        src, tgt = self.embedding(src) * math.sqrt(d_model), self.embedding(tgt) * math.sqrt(d_model)\n",
    "        src, tgt = self.pos_encoder(src), self.pos_encoder(tgt)\n",
    "\n",
    "        output = self.transformer(src, tgt, src_mask=src_mask, tgt_mask=tgt_mask, src_key_padding_mask=src_key_padding_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
    "        return self.output_layer(output)\n",
    "\n",
    "# MASKING\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = torch.ones(sz, sz)\n",
    "    mask = torch.triu(mask)\n",
    "    mask = (mask == 1)\n",
    "    mask = mask.transpose(0, 1)\n",
    "    mask = mask.float()\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf'))\n",
    "    mask = mask.masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters:  45071376\n",
      "tensor([0.0323, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645,\n",
      "        0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645, 0.0645],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        src = batch[\"input_ids\"].to(device)\n",
    "        tgt = batch[\"nikud\"].to(device)\n",
    "        padding_mask = batch[\"attention_mask\"].to(device)\n",
    "        # conver padding mask to boolean mask\n",
    "        padding_mask = padding_mask == 0\n",
    "        # convert padding mask to float\n",
    "        padding_mask = padding_mask.float()\n",
    "        \n",
    "        \n",
    "        tgt_input = tgt[:, :-1]\n",
    "        tgt_input_padding_mask = padding_mask[:, :-1]\n",
    "        tgt_output = tgt[:, 1:]\n",
    "        tgt_output_padding_mask = padding_mask[:, 1:]\n",
    "        seq_len = tgt_input.size(1)\n",
    "        tgt_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(src, tgt_input, tgt_mask=tgt_mask, src_key_padding_mask=padding_mask, tgt_key_padding_mask=tgt_input_padding_mask)\n",
    "        output = output.view(-1, output.shape[-1])\n",
    "        tgt_output = tgt_output.reshape(-1)\n",
    "        loss = criterion(output, tgt_output)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Accuracy\n",
    "        pred = output.argmax(1)\n",
    "        tgt_output_padding_mask = tgt_output_padding_mask.reshape(-1)\n",
    "        pred = pred[tgt_output_padding_mask == 0]\n",
    "        tgt_output = tgt_output[tgt_output_padding_mask == 0]\n",
    "        correct_predictions += (pred == tgt_output).sum().item()\n",
    "        total_predictions += tgt_output.numel()\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return total_loss / len(train_loader), accuracy\n",
    "\n",
    "def evaluate(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            src = batch[\"input_ids\"].to(device)\n",
    "            tgt = batch[\"nikud\"].to(device)\n",
    "            padding_mask = batch[\"attention_mask\"].to(device)\n",
    "            # conver padding mask to boolean mask\n",
    "            padding_mask = padding_mask == 0\n",
    "            # convert padding mask to float\n",
    "            padding_mask = padding_mask.float()\n",
    "            \n",
    "            tgt_input = tgt[:, :-1]\n",
    "            tgt_input_padding_mask = padding_mask[:, :-1]\n",
    "            tgt_output = tgt[:, 1:]\n",
    "            tgt_output_padding_mask = padding_mask[:, 1:]\n",
    "            seq_len = tgt_input.size(1)\n",
    "            tgt_mask = generate_square_subsequent_mask(seq_len).to(device)\n",
    "            \n",
    "            output = model.forward(src, tgt_input, tgt_mask=tgt_mask, src_key_padding_mask=padding_mask, tgt_key_padding_mask=tgt_input_padding_mask)\n",
    "            output = output.view(-1, output.shape[-1])\n",
    "            tgt_output = tgt_output.reshape(-1)\n",
    "            loss = criterion(output, tgt_output)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Accuracy\n",
    "            pred = output.argmax(1)\n",
    "            tgt_output_padding_mask = tgt_output_padding_mask.reshape(-1)\n",
    "            pred = pred[tgt_output_padding_mask == 0]\n",
    "            tgt_output = tgt_output[tgt_output_padding_mask == 0]\n",
    "            correct_predictions += (pred == tgt_output).sum().item()\n",
    "            total_predictions += tgt_output.numel()\n",
    "            print(\"pred: \", pred)\n",
    "            print(\"tgt_output: \", tgt_output)\n",
    "    \n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    return total_loss / len(val_loader), accuracy\n",
    "\n",
    "\n",
    "def generate(model, src, max_len):\n",
    "    model.eval()\n",
    "    outputs = []\n",
    "    \n",
    "    # Loop over each sequence in the batch\n",
    "    for s in src:\n",
    "        s = s.unsqueeze(0)  # Add batch dimension\n",
    "        original_len = s.size(1)  # Track original sequence length\n",
    "        tgt_init_tok = [1]  # Assuming 1 is the <SOS> token id\n",
    "        tgt = torch.LongTensor(tgt_init_tok).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Pad (or truncate) tgt to match the length of s\n",
    "        if tgt.size(1) < original_len:\n",
    "            padding_size = original_len - tgt.size(1)\n",
    "            padding = torch.zeros(tgt.size(0), padding_size).long().to(device)\n",
    "            tgt = torch.cat([tgt, padding], dim=1)\n",
    "        else:\n",
    "            tgt = tgt[:, :original_len]\n",
    "\n",
    "        for i in range(max_len):\n",
    "            tgt_mask = generate_square_subsequent_mask(tgt.size(1)).to(device)\n",
    "            output = model(s, tgt, tgt_mask=tgt_mask)\n",
    "            next_word = output.argmax(2)[-1, :].item()\n",
    "            tgt = tgt[:, :-1]  # Remove last token (either padding or previous token)\n",
    "            tgt = torch.cat([tgt, torch.LongTensor([next_word]).unsqueeze(0).to(device)], dim=1)\n",
    "            \n",
    "            if next_word == 2:  # Assuming 2 is the <EOS> token id\n",
    "                break\n",
    "        outputs.append(tgt.squeeze(1))  # Remove batch dimension\n",
    "        \n",
    "    return torch.stack(outputs, dim=0)  # Convert list of tensors to a single tensor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# hyperparameters\n",
    "epochs = 5\n",
    "\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "max_seq_length = 102\n",
    "batch_size = 32\n",
    "lr = 0.0001\n",
    "seed = 42\n",
    "vocab_size = alephbert_tokenizer.vocab_size\n",
    "num_classes = len(label_to_id)\n",
    "\n",
    "# set seed\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# create model\n",
    "model = TransformerModel(vocab_size, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, max_seq_length)\n",
    "model.to(device)\n",
    "print(\"number of parameters: \", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "# create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "label_weights = set_no_nikud_weight(0.5)\n",
    "label_weights = label_weights.values()\n",
    "label_weights = torch.tensor(list(label_weights)).to(device)\n",
    "print(label_weights)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=len(id_to_label), weight=label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:24<00:00,  4.54it/s]\n",
      "  0%|          | 0/29 [00:00<?, ?it/s]c:\\Users\\baruc\\anaconda3\\envs\\NLP\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "  7%|▋         | 2/29 [00:00<00:01, 15.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 7, 4,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([3, 0, 7,  ..., 7, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6/29 [00:00<00:01, 15.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 3, 0,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([7, 3, 2,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([2, 3, 0,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10/29 [00:00<00:01, 15.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([8, 7, 0,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 1, 9,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([7, 4, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 3, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [00:00<00:00, 15.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([4, 7, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([2, 3, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 3,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 18/29 [00:01<00:00, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 9, 9,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([8, 7, 0,  ..., 3, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:01<00:00, 15.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([7, 0, 1,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 3, 0,  ..., 4, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 7, 4,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 24/29 [00:01<00:00, 15.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 9,  ..., 9, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 0, 5,  ..., 4, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([3, 7, 4,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 2, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([2, 1, 7, 0, 7, 7, 0, 2, 6, 0, 5, 0, 3, 6, 0, 2, 1, 3, 2, 0, 0, 0, 5, 1,\n",
      "        2, 0, 0, 7, 0, 0, 0, 0, 2, 1, 7, 2, 0, 0, 2, 0, 3, 2, 0, 0, 0, 9, 0, 9,\n",
      "        7, 6, 3, 0, 1, 3, 6, 7, 0, 1, 0, 0, 1, 0, 0, 1, 9, 0, 0, 0, 0, 1, 7, 0,\n",
      "        0, 0, 0, 2, 0, 0, 0, 2, 1, 9, 3, 0, 0, 0, 1, 7, 1, 7, 7, 0, 9, 8, 7, 7,\n",
      "        0, 0, 1, 9, 0, 4, 5, 0, 4, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 9,\n",
      "        1, 7, 0, 1, 0, 5, 7, 7, 0, 3, 0, 7, 0, 0, 0, 0, 0, 0, 1, 5, 0, 2, 6, 3,\n",
      "        0, 0, 0, 9, 0, 1, 2, 1, 9, 0, 1, 9, 3, 6, 0, 7, 1, 7, 0, 0, 2, 0, 0, 0,\n",
      "        9, 7, 0, 0], device='cuda:0')\n",
      "Epoch 1: train loss 2.1344975539013347, val loss 2.0780074801938286\n",
      "Epoch 1: train acc 0.42153545951014304, val acc 0.44457907358323867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:25<00:00,  4.42it/s]\n",
      "  7%|▋         | 2/29 [00:00<00:01, 15.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 0,  ..., 0, 7, 5], device='cuda:0')\n",
      "tgt_output:  tensor([2, 7, 3,  ..., 6, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 1,  ..., 0, 6, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 9, 1,  ..., 5, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 7, 1,  ..., 7, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 9, 0,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6/29 [00:00<00:01, 15.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 8, 0,  ..., 1, 1, 0], device='cuda:0')\n",
      "tgt_output:  tensor([9, 0, 0,  ..., 2, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 8, 7,  ..., 0, 0, 5], device='cuda:0')\n",
      "tgt_output:  tensor([9, 8, 4,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 6, 1], device='cuda:0')\n",
      "tgt_output:  tensor([0, 2, 4,  ..., 5, 9, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10/29 [00:00<00:01, 15.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 7, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 7, 0,  ..., 4, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 4, 0,  ..., 0, 0, 7], device='cuda:0')\n",
      "tgt_output:  tensor([4, 0, 0,  ..., 3, 1, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 4, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 1,  ..., 4, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [00:00<00:00, 15.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 0,  ..., 0, 1, 0], device='cuda:0')\n",
      "tgt_output:  tensor([5, 0, 0,  ..., 2, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 1, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([2, 0, 2,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 7, 0, 5], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 3, 0,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 20/29 [00:01<00:00, 15.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 1,  ..., 7, 0, 7], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 3, 6, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 2, 3,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 7, 5,  ..., 0, 1, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 0, 0,  ..., 2, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 3, 0,  ..., 7, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:01<00:00, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 7,  ..., 5, 5, 6], device='cuda:0')\n",
      "tgt_output:  tensor([0, 1, 2,  ..., 0, 5, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 9, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 7,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 1, 9,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 5,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 0, 5,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 26/29 [00:01<00:00, 15.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 7, 5,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 0, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 8, 7,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([9, 1, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 0,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([2, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 0, 0,  ..., 1, 5, 5], device='cuda:0')\n",
      "tgt_output:  tensor([0, 7, 9,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 1, 7, 0, 0, 7, 0, 0, 0, 0, 1, 0, 0, 0, 7, 0, 7, 1, 0, 0, 0, 0, 0, 0,\n",
      "        0, 1, 7, 0, 0, 0, 7, 1, 0, 0, 1, 7, 1, 0, 7, 0, 0, 0, 7, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 7, 1, 7, 0,\n",
      "        0, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0, 7, 1, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0,\n",
      "        7, 1, 0, 7, 0, 7, 1, 0, 0, 7, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        7, 0, 1, 7, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 1, 7, 0, 0, 1, 7,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 7, 0, 0, 0, 0, 0, 1, 1, 7, 0, 0, 0, 0, 0, 0, 1, 7, 1, 0, 0, 6, 7, 7,\n",
      "        0, 0, 0, 1, 0, 4, 0, 1, 0, 7, 0, 6, 7, 1, 1, 7, 4, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 7, 0, 5, 7, 1, 7, 0, 0, 5, 7, 1, 5, 4, 1, 7, 1, 0, 7,\n",
      "        5, 7, 0, 5], device='cuda:0')\n",
      "tgt_output:  tensor([ 9,  8,  3,  0,  1,  7,  0,  4,  0,  9,  2,  7,  0,  1,  4, 11,  9,  0,\n",
      "         4,  3,  0,  0,  4,  0,  9,  1,  3,  0,  5,  6,  9,  0,  0,  9,  1,  9,\n",
      "         0,  1,  2,  0,  2,  1,  3,  0,  0,  0,  0,  4,  0,  3,  0,  0,  5,  9,\n",
      "         0,  7,  7,  0,  0,  0,  0,  9,  9,  0,  9,  9,  0,  1,  2,  1,  4,  0,\n",
      "         7,  1,  2,  0,  4,  7,  8,  2,  0,  0,  1,  9,  4,  4,  0,  7,  1,  0,\n",
      "         0,  0,  0,  0,  0,  1,  9,  0,  1,  2,  1,  9,  0,  2,  6,  3,  1,  2,\n",
      "         0,  0,  5,  7,  0,  7,  7,  0,  0,  0,  0,  1,  4,  2,  1,  9,  0,  9,\n",
      "         2,  0,  0,  5,  7,  0,  0,  0,  0,  0,  1,  9,  8,  3,  0,  9,  1,  2,\n",
      "         0,  7,  0,  0,  0,  0,  0,  0,  2,  3,  0,  0,  0,  0,  2,  0,  0,  3,\n",
      "         0,  0,  5,  3,  0,  2,  1,  0,  0,  0,  5,  0,  0,  2,  6,  0,  5,  0,\n",
      "         0,  0,  4,  9,  1,  9,  3,  0, 10,  6,  1,  7,  0,  7,  9,  0,  4,  7,\n",
      "         9,  0,  1,  0,  5,  1,  9,  2,  1,  4,  0,  0,  7,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  2,  1,  7,  0,  1,  9,  1,  7,  7,  0,  1,  9,  0,  4,\n",
      "         2,  1,  9,  3,  6,  0,  1,  7,  0,  0], device='cuda:0')\n",
      "Epoch 2: train loss 1.957592836523478, val loss 1.9314521181172337\n",
      "Epoch 2: train acc 0.4317925520457166, val acc 0.37432790609617567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:25<00:00,  4.36it/s]\n",
      "  7%|▋         | 2/29 [00:00<00:01, 15.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 9, 6,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 2, 1,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 0, 1, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 9, 0,  ..., 9, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 6,  ..., 5, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 5, 9,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 0,  ..., 4, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([2, 0, 7,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6/29 [00:00<00:01, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([ 1,  1, 11,  4, 11,  0,  1,  7,  5,  5,  0,  0,  0,  0, 11,  0,  0, 11,\n",
      "         0,  6,  1,  0,  0,  0,  1,  1,  0,  1,  0,  1,  1,  0,  0,  1,  7,  6,\n",
      "         0,  6,  0,  0,  1,  1,  1,  1,  1,  1,  6,  0,  1,  1,  7,  0,  0,  0,\n",
      "         1,  7,  4,  0,  0,  0,  0,  6,  0,  6,  4,  0,  4,  7,  0,  0,  1,  0,\n",
      "         0,  6,  0,  1,  1,  0,  0,  0,  0,  1,  1,  6,  0,  6,  0,  1,  8,  7,\n",
      "         7,  1,  0,  1,  9,  0,  1,  1,  1,  1,  7,  0,  0,  0,  0,  0,  0,  1,\n",
      "         0,  6,  0,  0,  7,  1,  7,  1,  7,  0,  0,  0,  0,  0,  1,  7,  1,  7,\n",
      "         0,  0,  1,  1,  1,  1,  7,  0,  1,  1,  7,  6,  7,  0,  1,  0,  0,  1,\n",
      "         9,  0,  3, 11,  5, 11,  5,  1,  1,  7,  0,  5,  0,  6,  5,  5,  6,  0,\n",
      "         0,  1,  1,  7,  0,  7,  0,  0,  0,  1,  7,  0,  0,  0,  0,  0,  7,  1,\n",
      "         0,  1,  7,  0,  0,  1,  0,  0,  0,  7,  0,  7,  0,  0,  1,  0,  7,  7,\n",
      "         7,  0,  0,  1,  0,  0,  0,  7,  0,  0,  1,  0,  0,  0,  0,  0,  1,  7,\n",
      "         0,  0,  0,  7,  0,  0,  0,  0,  7,  1,  0,  1,  7,  0,  1,  6,  0,  6,\n",
      "        11,  1,  7,  7,  0,  0,  6,  7,  1,  7,  5,  0,  6,  7, 11, 11,  0,  1,\n",
      "         9,  0,  1,  7,  0,  1,  0,  0,  0,  1,  7,  0,  6,  0,  6,  0,  1,  0,\n",
      "         0,  0,  7,  1,  0,  6,  0,  0,  1,  7,  0,  7,  0,  6,  0,  0,  0,  1,\n",
      "         1,  9,  0,  1,  1,  7,  1,  0,  0,  0,  0,  0,  0,  3,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  7,  1,  0,  0,  0,  0,\n",
      "         0,  0,  1,  9,  0,  5, 11,  6,  5, 11,  7,  1,  5,  5,  5,  5,  0,  0,\n",
      "         1,  9,  5,  5,  5,  5,  6,  0,  0,  7,  0,  0,  1,  7,  1,  0,  0,  0,\n",
      "         0,  7,  0,  0,  7,  0,  0,  0,  0,  0,  0,  1,  1,  7,  0,  1,  0,  1,\n",
      "         0,  6,  0,  0,  1,  7,  0,  0,  0,  7,  1,  7,  0,  0,  0,  1,  1,  1,\n",
      "         1,  1,  7,  0,  0,  0,  1,  0,  0,  0,  0,  0,  1,  7,  6,  0, 11,  7,\n",
      "         0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  0,  1,  0,  1,  1,\n",
      "         1,  1,  0,  0,  0,  1,  7,  6,  0,  0,  4,  0,  0,  0,  0,  6,  7,  0,\n",
      "         0,  0,  7,  0,  0,  1,  7,  1,  7,  0,  0,  0,  0,  1,  8,  7,  0,  5,\n",
      "         0, 11,  0,  1,  0,  0,  6,  0,  7,  1,  0,  1,  0,  1,  1,  1,  1,  7,\n",
      "         0,  6,  5, 11, 11,  5,  1,  1,  7,  0,  5,  0,  1,  0,  1,  0,  0,  6,\n",
      "         0,  1,  0,  0,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         7,  6,  7,  0,  0,  7,  0,  0,  0,  0,  1,  7,  0,  7,  0,  3,  1,  7,\n",
      "         0,  1,  1,  0,  1,  0,  7,  1,  7,  0,  0,  0,  1,  7,  0,  7,  0,  7,\n",
      "         1,  0,  0,  7,  1,  1,  0,  1,  7,  7,  0,  6,  6,  0,  0,  0,  0,  1,\n",
      "         7,  0,  0,  0,  6,  7,  1,  7,  0,  1,  1,  1,  1,  1,  9,  6,  5,  5,\n",
      "         5,  5,  9, 11,  7, 11,  5,  1,  5,  0,  0,  0,  0,  7,  1,  1,  0,  0,\n",
      "         1,  7,  0,  0,  0,  1,  1,  1,  0,  1, 11,  7,  0,  5,  7,  1,  5,  0,\n",
      "         5,  5,  7,  6,  7,  1,  0,  1,  7,  1,  0,  0,  0,  0,  1,  1,  1,  0,\n",
      "         4,  0,  1,  0,  0,  1,  1,  0,  1,  1,  1,  1,  0,  1,  0,  1, 11, 11,\n",
      "        11,  7,  5,  5,  5,  5,  5,  0,  3,  1,  5,  6,  6,  0,  0,  0,  0,  0,\n",
      "         1,  0,  7,  0,  1,  0,  0,  1,  1,  7,  7,  0,  0,  0,  0,  1,  0,  7,\n",
      "         6,  0,  0,  0,  1,  1,  7,  0,  1,  0,  0,  1,  8,  1,  7,  0,  0,  1,\n",
      "         0,  0,  1,  7,  0,  5,  0,  1,  0,  0,  7,  1,  1,  0,  0,  6,  0,  1,\n",
      "         0,  7,  7,  1,  6,  7,  1,  0,  0,  1,  0,  1,  7,  1,  1,  0,  0,  0,\n",
      "         0,  7,  0,  0,  7,  0,  6,  7,  1,  0,  0,  1,  7,  7,  0,  0,  1,  9,\n",
      "         0,  5,  0,  7,  1,  0,  0,  1,  0,  0,  0,  7,  1,  7,  7,  0,  0,  7,\n",
      "         6,  0,  1,  7,  7,  0,  0,  1,  0,  0,  1,  0,  0,  0, 11,  0,  0,  0,\n",
      "         0,  0,  3,  0,  0,  0,  7,  1,  7,  0,  5,  1,  1,  7,  0,  0,  0,  0,\n",
      "         0,  0,  7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  1,  0,  7,  0,  0,  1,  0,  1,  1,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  1,  0,  7,  0,  0,  1,  0,  7,  0,  7,  0,  0,  0,  0,  0,  7,\n",
      "         0,  0,  0,  0,  0,  0,  1,  7,  0,  1,  1,  0,  7,  0,  0,  7,  0,  1,\n",
      "         7,  1,  0,  0,  0,  0,  0,  7,  0,  0,  0,  0,  0,  7,  1,  7,  7,  0,\n",
      "         0,  0,  0,  1,  7,  0,  0,  7,  0,  0,  0,  7,  0,  0,  0,  7,  1,  0,\n",
      "         1,  6,  7,  7,  0,  0,  0,  0,  0,  1,  7,  1,  0,  1,  6,  7,  7,  0,\n",
      "         0], device='cuda:0')\n",
      "tgt_output:  tensor([ 0,  4, 11,  4,  0,  2,  1,  0,  0,  7,  7,  3,  0,  4,  7,  0,  4,  0,\n",
      "         5,  2,  0,  0,  0,  9,  9,  0,  0,  7,  0,  2,  0,  0,  9,  1,  2,  0,\n",
      "         2,  0,  0,  0,  0,  0,  0,  0,  0,  5,  3,  9,  2,  6,  0,  0,  0,  9,\n",
      "         1,  4,  0,  3,  0,  0,  5,  0,  5,  4,  0,  4,  1,  3,  0,  9,  0,  0,\n",
      "         5,  3,  9,  9,  7,  0,  0,  0,  0,  0,  5,  0,  5,  0,  2,  9,  6,  1,\n",
      "         2,  0,  0,  1,  7,  9,  0,  9,  2,  6,  0,  0,  0,  3,  0,  0,  9,  0,\n",
      "         5,  3,  0,  1,  9,  1,  9,  1,  7,  0,  3,  0,  0,  9,  1,  9,  1,  3,\n",
      "         0,  0,  0,  0,  2,  1,  7,  0,  2,  1, 10,  6,  7,  0,  0,  0,  0,  1,\n",
      "         9,  8,  4,  0,  4,  0,  9,  9,  8,  7,  0,  7,  2,  0,  0,  5,  7,  0,\n",
      "         0,  2,  1,  2,  0,  0,  0,  0,  9,  1,  7,  0,  4,  0,  7,  1,  9,  0,\n",
      "         9,  8,  5,  0,  9,  7,  0,  0,  1,  7,  1,  5,  0,  9,  7,  6,  1,  1,\n",
      "         3,  0,  9,  0,  0,  0,  1,  7,  0,  9,  7,  0,  4,  7,  0,  2,  1,  0,\n",
      "         5,  0,  1,  3,  0,  5,  0,  1,  9,  0,  0,  8,  7,  0,  2,  0,  2,  4,\n",
      "         2,  1,  8,  7,  0,  2,  1,  9,  1,  0,  0, 10,  6,  4,  4,  0,  0,  1,\n",
      "         7,  0,  1,  7,  2,  0,  0,  0,  2,  1,  0,  5,  0,  5,  0,  9,  0,  0,\n",
      "         0,  1,  9,  0,  5,  3,  0,  9,  8,  3,  6,  0,  5,  7,  7,  0,  0,  0,\n",
      "         1,  7,  0,  2,  1,  2,  0,  0,  0,  0,  0,  0,  5,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  0,  1,  2,  0,  0,  7,  7,  0,\n",
      "         0,  0,  1,  9,  0,  4,  5,  0,  4,  1,  2,  0,  0,  0,  0,  0,  0,  0,\n",
      "         1,  0,  0,  0,  0,  5,  3,  0,  1,  7,  7,  0,  1, 12,  0,  7,  3,  0,\n",
      "         1,  7,  3,  6,  0,  0,  0,  0,  0,  0,  0,  2,  1,  7,  0,  7,  0,  0,\n",
      "         5,  7,  0,  2,  6,  0,  0,  0,  1,  9,  1,  7,  7,  0,  0,  0,  0,  0,\n",
      "         2,  6,  0,  0,  0,  2,  0,  0,  0,  0,  0,  9,  1,  3,  0,  4,  1,  7,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  0,  7,  0,  0,  0,\n",
      "         2,  0,  0,  0,  9,  8,  2,  0,  7,  4,  0,  3,  0,  0,  5,  1,  0,  0,\n",
      "         0,  1,  7,  0,  2,  6,  9,  1,  7,  0,  0,  0,  0,  9,  1,  6,  0,  0,\n",
      "         4,  7,  9,  0,  0,  5,  0,  1,  2,  0,  2,  0,  0,  0,  0,  2,  1,  9,\n",
      "         3,  0,  4,  4,  0,  0,  2,  1,  9,  0,  7,  9,  0,  9,  7,  0,  5,  0,\n",
      "         9,  7,  0,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
      "         5,  6,  7,  0,  1,  0,  0,  7,  0,  0,  1,  3,  0,  0,  5,  9,  8,  7,\n",
      "         0,  2,  0,  2,  0,  1,  9,  1,  4,  0,  0,  9,  1,  7,  6,  0,  1,  2,\n",
      "         7,  3,  1,  9,  9,  0,  2,  6,  1,  0,  5,  5,  0,  7,  3,  0,  2,  6,\n",
      "         0,  0,  0,  5,  1,  9,  1,  3,  9,  0,  0,  0,  0,  1,  5,  0,  0,  0,\n",
      "         0,  1,  4, 11,  4,  0,  2,  0,  7,  0,  0,  0,  1,  9,  9,  0,  3,  2,\n",
      "         6,  7,  7,  0,  0,  0,  0,  3,  0,  4,  1,  3,  0,  1,  9,  0,  3,  0,\n",
      "         0,  1, 10,  6,  9,  0,  9,  1,  2,  0,  3,  0,  0,  9,  9,  2,  0,  4,\n",
      "         7,  2,  0,  0,  9,  9,  0,  0,  0,  0,  0,  3,  0,  7,  0,  4,  4,  4,\n",
      "         1,  0,  0,  0,  0,  0,  0,  8,  9,  0,  2,  2,  0,  0,  0,  0,  0,  0,\n",
      "         3,  6,  3,  0,  0,  0,  2,  9,  1,  1,  0,  0,  7,  0,  9,  0,  1,  2,\n",
      "         0,  0,  0,  0,  2,  1,  7,  0,  0,  0,  0,  9,  2,  6,  0,  0,  2,  0,\n",
      "         0,  0,  1,  4,  0,  7,  0,  0,  0,  1,  9,  9,  7,  0,  5,  0,  9,  7,\n",
      "         6,  1,  9,  5,  8,  2,  0,  0,  9,  0,  9,  1,  2,  2,  0,  0,  0,  0,\n",
      "         1,  7,  0,  1,  0,  5,  1,  2,  0,  0,  9,  1,  6,  3,  0,  0,  1,  9,\n",
      "         0,  7,  1,  2,  0,  0,  2,  0,  0,  0,  1,  9,  1,  6,  0,  0,  1,  2,\n",
      "         0,  9,  1,  6,  0,  0,  0,  7,  3,  0,  0,  0,  0,  4,  7,  0,  3,  0,\n",
      "         0,  8,  7,  7,  0,  1,  9,  1,  7,  0,  0,  2,  1,  7,  0,  0,  0,  7,\n",
      "         0,  1,  3,  0,  0,  0,  0,  0,  0,  0,  0,  9,  7,  0,  5,  0,  0,  0,\n",
      "         0,  0,  9,  0,  1,  0,  5,  2,  0,  9,  2,  0,  0,  5,  4,  0,  0,  0,\n",
      "         0,  9,  0,  1,  3,  0,  9,  0,  1,  3,  6,  7,  0,  4,  0,  5,  1,  7,\n",
      "         0,  0,  0,  0,  0,  0,  8,  7,  0,  9,  2,  1,  4,  0,  1,  7,  9,  1,\n",
      "         9,  0,  0,  0,  0,  4,  1,  7,  7,  0,  0,  0,  1,  2,  6,  1,  7,  0,\n",
      "         0,  5,  2,  6,  7,  0,  1,  0,  5,  3,  6,  0,  0,  0,  1,  9,  0,  9,\n",
      "        10,  6,  1,  7,  0,  7,  4,  0,  2,  1,  9,  0,  9, 10,  6,  1,  7,  0,\n",
      "         0], device='cuda:0')\n",
      "pred:  tensor([1, 9, 0,  ..., 0, 0, 7], device='cuda:0')\n",
      "tgt_output:  tensor([1, 9, 0,  ..., 0, 1, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10/29 [00:00<00:01, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 0,  ..., 0, 1, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 7, 4,  ..., 9, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 7,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([2, 1, 9,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 7, 9,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 9, 6,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 2, 7,  ..., 7, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [00:00<00:01, 14.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 9, 0,  ..., 6, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 9, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 7,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([2, 1, 7,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 9, 0,  ..., 7, 0, 5], device='cuda:0')\n",
      "tgt_output:  tensor([1, 7, 5,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 6, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([10,  6,  1,  ...,  7,  0,  0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 18/29 [00:01<00:00, 14.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 7,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([9, 1, 2,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 0,  ..., 7, 1, 0], device='cuda:0')\n",
      "tgt_output:  tensor([9, 0, 3,  ..., 2, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 7,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([9, 8, 2,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 7,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([9, 1, 2,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:01<00:00, 14.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 1,  ..., 7, 0, 6], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 5, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 7, 2,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 1,  ..., 3, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 24/29 [00:01<00:00, 14.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 1,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([8, 7, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 7, 0,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 1,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 7, 6, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 4, 0,  ..., 2, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 9, 6,  ..., 7, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 2, 1,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1, 1, 1, 7, 5, 6, 0, 1, 1, 4, 0, 7, 1, 0, 0, 0, 7, 1, 7, 0, 0, 0,\n",
      "        0, 0, 4, 0, 0, 0, 1, 0, 7, 0, 0, 1, 7, 0, 7, 0, 0, 1, 7, 0, 0, 1, 7, 6,\n",
      "        1, 0, 0, 0, 0, 7, 0, 0, 0, 1, 0, 0, 7, 1, 1, 0, 1, 7, 1, 0, 0, 1, 0, 0,\n",
      "        1, 1, 0, 0, 0, 7, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 7, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 1, 1, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 1, 7, 1, 0, 0,\n",
      "        0, 1, 1, 1, 1, 1, 1, 1, 9, 6, 1, 0, 1, 1, 7, 0, 1, 1, 1, 6, 1, 7, 0, 0,\n",
      "        1, 7, 1, 1, 0, 1, 1, 0, 7, 1, 1, 7, 0, 1, 1, 0, 0, 7, 0, 0, 6, 7, 0, 0,\n",
      "        0, 0, 7, 6, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([ 0,  0,  0,  2,  1,  0,  5,  7,  0,  2,  4,  0,  1,  2,  0,  7,  0,  1,\n",
      "         2,  1,  3,  0,  7,  7,  0,  4,  3,  3,  0,  2,  0,  1,  7,  0,  9,  8,\n",
      "         3,  6,  7,  0,  0,  1,  7,  4,  0,  8,  5,  0,  7,  0,  5,  0,  1,  7,\n",
      "         3,  0,  9,  7,  0,  1,  9,  9,  0,  9,  1,  2,  0,  0,  9,  7,  0,  9,\n",
      "         9,  0,  0,  5,  1,  3,  0,  9,  7,  0,  5,  0,  4,  7,  0,  2,  1,  7,\n",
      "         0,  4,  9,  0,  4,  7,  0,  9,  9,  0,  0,  1,  3,  0,  0,  5,  7,  0,\n",
      "         5,  0,  1,  7,  3,  0,  2,  1,  2,  0,  7,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  1, 10,  6,  7,  0,  9,  8,  7,  0,  0,  0, 10,  6,  1,  7,  7,  0,\n",
      "         1,  0,  0,  7,  0,  0,  3,  6,  9,  0,  1,  7,  0,  9,  0,  0,  1,  7,\n",
      "         0,  2,  1,  0,  0,  7,  0,  1,  2,  0,  0,  0], device='cuda:0')\n",
      "Epoch 3: train loss 1.893577451199557, val loss 1.9158423070249886\n",
      "Epoch 3: train acc 0.43490959313744126, val acc 0.37170263788968827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:26<00:00,  4.32it/s]\n",
      "  7%|▋         | 2/29 [00:00<00:01, 15.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 1,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 2, 5,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([8, 7, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 1], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 2,  ..., 4, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6/29 [00:00<00:01, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 2,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 1, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 7, 8, 0], device='cuda:0')\n",
      "tgt_output:  tensor([7, 7, 0,  ..., 9, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 2, 6,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 5, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([ 0,  0,  2,  ..., 11,  0,  0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 1, 0,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10/29 [00:00<00:01, 15.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 0, 1,  ..., 0, 5, 5], device='cuda:0')\n",
      "tgt_output:  tensor([7, 0, 7,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 5, 6, 5], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 3,  ..., 5, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 7,  ..., 6, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([2, 0, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 2, 0,  ..., 5, 0, 5], device='cuda:0')\n",
      "tgt_output:  tensor([1, 2, 1,  ..., 5, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [00:00<00:00, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 1,  ..., 7, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 2, 5,  ..., 8, 6, 5], device='cuda:0')\n",
      "tgt_output:  tensor([1, 0, 5,  ..., 3, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([8, 3, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 2, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 3, 6,  ..., 0, 5, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 18/29 [00:01<00:00, 14.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 2, 0,  ..., 8, 0, 5], device='cuda:0')\n",
      "tgt_output:  tensor([1, 4, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 2, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 3, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 2, 0,  ..., 8, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 7, 4,  ..., 7, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 22/29 [00:01<00:00, 14.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([ 1, 11,  0,  ...,  0,  0,  0], device='cuda:0')\n",
      "tgt_output:  tensor([4, 7, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 7,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([0, 7, 0,  ..., 5, 5, 6], device='cuda:0')\n",
      "tgt_output:  tensor([7, 0, 7,  ..., 0, 5, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 26/29 [00:01<00:00, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([0, 2, 0,  ..., 1, 1, 1], device='cuda:0')\n",
      "tgt_output:  tensor([1, 3, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 2, 5,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 2,  ..., 1, 0, 1], device='cuda:0')\n",
      "tgt_output:  tensor([0, 1, 9,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 2,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 1, 7,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([ 1,  1,  7,  ..., 11, 11,  7], device='cuda:0')\n",
      "tgt_output:  tensor([2, 0, 2,  ..., 4, 1, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 8, 7, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 2, 6, 1,\n",
      "        1, 1, 1, 2, 0, 1, 6, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 7, 1, 0, 0, 0, 0, 0, 0, 0, 7, 1, 7, 0, 0,\n",
      "        1, 1, 1, 1, 7, 0, 1, 1, 1, 1, 1, 7, 0, 1, 0, 1, 1, 1, 7, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 0, 1, 7, 1, 7, 0, 0, 7, 0, 0, 0, 0, 7, 1, 0, 0, 0, 7, 1, 7, 0,\n",
      "        0, 7, 0, 0, 0, 6, 7, 0, 0, 0, 0, 7, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 1, 0, 7, 1, 7, 0, 0, 0, 1, 0, 1, 7, 0, 0, 0, 2, 0, 5, 6, 9, 1,\n",
      "        7, 1, 7, 7, 5, 5, 1, 5, 0, 0, 5, 0, 5, 7, 0, 7, 1, 0, 7, 7, 1, 6, 1, 7,\n",
      "        0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 7, 0, 1, 0, 1, 1, 0, 7, 0, 7, 1, 0, 0,\n",
      "        7, 1, 0, 1, 0, 2, 1, 1, 0, 0, 1, 7, 0, 7, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 0, 1, 0, 2, 0, 1, 7, 0, 7, 0, 1, 0, 1, 0, 1, 1, 7, 1, 0, 0, 1],\n",
      "       device='cuda:0')\n",
      "tgt_output:  tensor([ 0,  4, 11,  4,  0,  3,  0,  0,  0,  7,  0,  0,  0,  7,  9,  1,  9,  0,\n",
      "         9,  0,  1,  3,  0,  0,  0,  0,  1,  7,  0,  3,  0,  0,  4,  5,  0,  2,\n",
      "         0,  9,  0,  0,  0,  0,  3,  0,  0,  4,  5,  0,  0,  5,  9,  0,  0,  0,\n",
      "         3,  0,  0,  1,  2,  0,  7,  0,  0,  3,  0,  0,  1,  9,  1,  7,  0,  0,\n",
      "         0,  0,  0,  4,  5,  0,  5,  0,  9,  0,  1,  3,  0,  7,  0,  4,  2,  1,\n",
      "         2,  0,  0,  7,  0,  2,  0,  0,  0,  9,  1,  2,  6,  7,  0,  1,  0,  0,\n",
      "         7,  0,  1,  2,  0,  0,  5,  1,  2,  6,  0,  0,  1,  7,  7,  0, 10,  6,\n",
      "         0,  5,  0,  0,  1,  9,  0,  4,  7,  0,  0,  0,  7,  0, 12,  0,  9,  0,\n",
      "         4,  7,  2,  0,  1,  2,  1,  0,  5,  0,  2,  0,  9,  1,  7,  0,  0,  1,\n",
      "         2,  0,  5,  0,  2,  1,  9,  1,  6,  0,  0,  9,  0,  5,  7,  0,  5,  0,\n",
      "         1,  7,  1,  0,  3,  0,  1,  9,  3,  0,  1,  7,  0,  3,  0,  7,  7,  0,\n",
      "         4,  2,  0,  4,  1,  7,  0,  7,  0,  0,  4, 11,  5,  6,  0,  7,  4,  1,\n",
      "         0,  5,  9,  3,  8,  9,  0,  7,  3,  0,  1,  3,  6,  7,  0,  4,  3,  2,\n",
      "         0,  7,  0,  9,  3,  0,  7,  0,  4,  8,  3,  0,  1,  3,  6,  7,  0,  3,\n",
      "         0,  7,  0,  2,  1,  9,  4,  4,  0,  0], device='cuda:0')\n",
      "Epoch 4: train loss 1.8804315085959646, val loss 1.9197269760329148\n",
      "Epoch 4: train acc 0.43503630212490974, val acc 0.36241322731288655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:26<00:00,  4.31it/s]\n",
      "  7%|▋         | 2/29 [00:00<00:01, 14.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 7,  ..., 8, 8, 5], device='cuda:0')\n",
      "tgt_output:  tensor([2, 0, 0,  ..., 9, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 9,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6/29 [00:00<00:01, 14.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 9,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 1, 9,  ..., 0, 5, 0], device='cuda:0')\n",
      "pred:  tensor([1, 7, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([8, 7, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([ 1,  9, 11,  ...,  0,  0,  0], device='cuda:0')\n",
      "tgt_output:  tensor([7, 4, 0,  ..., 5, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 8/29 [00:00<00:01, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 9, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 3, 0,  ..., 7, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 12/29 [00:00<00:01, 14.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 9, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 4, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([ 1,  1,  7,  ..., 11, 11,  5], device='cuda:0')\n",
      "tgt_output:  tensor([5, 6, 4,  ..., 4, 0, 0], device='cuda:0')\n",
      "pred:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [00:00<00:01, 14.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 8, 6,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([9, 1, 6,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 9, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 9, 9,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([ 1,  1,  1,  ...,  7, 11,  0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 4, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 18/29 [00:01<00:00, 14.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([ 1,  1,  1,  ...,  6, 11,  5], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 2,  ..., 4, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 9, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 7, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 20/29 [00:01<00:00, 14.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 1,  ..., 1, 1, 1], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 7, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 9,  ..., 4, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 7,  ..., 7, 0, 1], device='cuda:0')\n",
      "tgt_output:  tensor([2, 1, 2,  ..., 7, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 24/29 [00:01<00:00, 14.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 1,  ..., 1, 1, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 9, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 9, 3,  ..., 1, 1, 6], device='cuda:0')\n",
      "tgt_output:  tensor([1, 7, 9,  ..., 0, 5, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 7, 0, 0], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 26/29 [00:01<00:00, 14.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred:  tensor([1, 1, 7,  ..., 0, 0, 1], device='cuda:0')\n",
      "tgt_output:  tensor([2, 1, 9,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([ 1,  9, 11,  ...,  0,  0,  0], device='cuda:0')\n",
      "tgt_output:  tensor([1, 4, 0,  ..., 7, 0, 0], device='cuda:0')\n",
      "pred:  tensor([1, 1, 1,  ..., 1, 0, 0], device='cuda:0')\n",
      "tgt_output:  tensor([0, 0, 0,  ..., 0, 5, 0], device='cuda:0')\n",
      "pred:  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 14.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 9,  ..., 1, 1, 1], device='cuda:0')\n",
      "tgt_output:  tensor([0, 1, 7,  ..., 0, 0, 0], device='cuda:0')\n",
      "pred:  tensor([ 1,  1,  1,  9,  6,  1,  0,  1,  0,  1,  1,  3,  9,  6,  1,  0,  1,  0,\n",
      "         1,  0,  1,  1,  1,  7,  7,  0,  1,  0,  0,  1,  1,  1,  1,  1,  0,  7,\n",
      "         0,  1,  7,  1,  1,  0,  7,  0,  1,  7,  0,  1,  7,  1,  0,  1,  7,  0,\n",
      "         0,  1,  0,  1,  1,  1,  7,  0,  1,  1,  1,  0,  0,  0,  0,  1,  9,  0,\n",
      "         0,  1,  1,  1,  1,  7,  0,  1,  0,  0,  1,  1,  7,  1,  0,  0,  0,  7,\n",
      "         0,  0,  1,  7,  1,  0,  1,  7,  0,  7,  0,  1,  7,  0,  0,  0,  0,  0,\n",
      "         0,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  0,\n",
      "         0,  3,  0,  1,  1,  1,  1,  1, 11,  0,  0,  0,  1,  9,  1,  0,  1],\n",
      "       device='cuda:0')\n",
      "tgt_output:  tensor([ 0,  0,  1, 10,  6,  7,  0,  3,  0,  0,  5,  1, 10,  6,  7,  0,  2,  6,\n",
      "         3,  0,  0,  9,  1,  1,  2,  0,  7,  7,  0,  0,  0,  2,  0,  0,  8,  7,\n",
      "         0,  1,  9,  0,  2,  1,  7,  0,  1,  7,  0,  1,  9,  3,  0,  1,  3,  7,\n",
      "         0,  7,  0,  0,  0,  1,  2,  0,  0,  0,  5,  2,  0,  0,  0,  1,  7,  4,\n",
      "         0,  2,  0,  4,  1,  7,  0,  0,  5,  9,  0,  1,  2,  0,  0,  0,  1,  7,\n",
      "         0,  2,  6,  9,  0,  2,  1,  5,  6,  0,  2,  1,  5,  6,  0,  0,  0,  0,\n",
      "         2,  0,  9,  5,  4,  0,  0,  5,  7,  0,  0,  0,  0,  0,  5,  0,  0,  0,\n",
      "         8,  7,  0,  0,  0,  0,  0,  4,  0,  0,  0,  2,  1,  9,  7,  0,  0],\n",
      "       device='cuda:0')\n",
      "Epoch 5: train loss 1.8631522096363844, val loss 1.892999163989363\n",
      "Epoch 5: train acc 0.43655047452515805, val acc 0.37170263788968827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train and validate\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion)\n",
    "    # print losses and accuracies for each epoch\n",
    "    print(f'Epoch {epoch + 1}: train loss {train_loss}, val loss {val_loss}')\n",
    "    print(f'Epoch {epoch + 1}: train acc {train_acc}, val acc {val_acc}')\n",
    "    # append losses and accuracies (for plotting later)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(val_losses, label='val')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# plot accuracies\n",
    "plt.plot(train_accs, label='train')\n",
    "plt.plot(val_accs, label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for batch in test_loader:\n",
    "    src = batch[\"input_ids\"].to(device)\n",
    "    prediction = generate(model, src, max_seq_length)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "# Convert predictions to whatever format you need for further processing or analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_random_data(n):\n",
    "#     SOS_token = np.array([2])\n",
    "#     EOS_token = np.array([3])\n",
    "#     length = 8\n",
    "\n",
    "#     data = []\n",
    "\n",
    "#     # 1,1,1,1,1,1 -> 1,1,1,1,1\n",
    "#     for i in range(n // 3):\n",
    "#         X = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
    "#         y = np.concatenate((SOS_token, np.ones(length), EOS_token))\n",
    "#         data.append([X, y])\n",
    "\n",
    "#     # 0,0,0,0 -> 0,0,0,0\n",
    "#     for i in range(n // 3):\n",
    "#         X = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
    "#         y = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n",
    "#         data.append([X, y])\n",
    "\n",
    "#     # 1,0,1,0 -> 1,0,1,0,1\n",
    "#     for i in range(n // 3):\n",
    "#         X = np.zeros(length)\n",
    "#         start = random.randint(0, 1)\n",
    "\n",
    "#         X[start::2] = 1\n",
    "\n",
    "#         y = np.zeros(length)\n",
    "#         if X[-1] == 0:\n",
    "#             y[::2] = 1\n",
    "#         else:\n",
    "#             y[1::2] = 1\n",
    "\n",
    "#         X = np.concatenate((SOS_token, X, EOS_token))\n",
    "#         y = np.concatenate((SOS_token, y, EOS_token))\n",
    "\n",
    "#         data.append([X, y])\n",
    "\n",
    "#     np.random.shuffle(data)\n",
    "\n",
    "#     return data\n",
    "\n",
    "\n",
    "# def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n",
    "#     batches = []\n",
    "#     for idx in range(0, len(data), batch_size):\n",
    "#         # We make sure we dont get the last bit if its not batch_size size\n",
    "#         if idx + batch_size < len(data):\n",
    "#             # Here you would need to get the max length of the batch,\n",
    "#             # and normalize the length with the PAD token.\n",
    "#             if padding:\n",
    "#                 max_batch_length = 0\n",
    "\n",
    "#                 # Get longest sentence in batch\n",
    "#                 for seq in data[idx : idx + batch_size]:\n",
    "#                     if len(seq) > max_batch_length:\n",
    "#                         max_batch_length = len(seq)\n",
    "\n",
    "#                 # Append X padding tokens until it reaches the max length\n",
    "#                 for seq_idx in range(batch_size):\n",
    "#                     remaining_length = max_bath_length - len(data[idx + seq_idx])\n",
    "#                     data[idx + seq_idx] += [padding_token] * remaining_length\n",
    "\n",
    "#             batches.append(np.array(data[idx : idx + batch_size]).astype(np.int64))\n",
    "\n",
    "#     # print(f\"{len(batches)} batches of size {batch_size}\")\n",
    "\n",
    "#     return batches\n",
    "\n",
    "\n",
    "# train_data = generate_random_data(9000)\n",
    "# val_data = generate_random_data(3000)\n",
    "\n",
    "# train_dataloader = batchify_data(train_data)\n",
    "# val_dataloader = batchify_data(val_data)\n",
    "\n",
    "# for batch in train_dataloader:\n",
    "#     X, y = batch[:, 0], batch[:, 1]\n",
    "#     X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
    "\n",
    "#     # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "#     y_input = y[:,:-1]\n",
    "#     y_expected = y[:,1:]\n",
    "#     print(\"X.shape: \", X.shape)\n",
    "#     print(\"X: \", X)\n",
    "#     print(\"y_input.shape: \", y_input.shape)\n",
    "#     print(\"y_input: \", y_input)\n",
    "#     print(\"y_expected.shape: \", y_expected.shape)\n",
    "#     print(\"y_expected: \", y_expected)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 56\u001b[0m\n\u001b[0;32m     53\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     55\u001b[0m \u001b[39m# Shift the decoder tokens right (this is a common practice in transformer models)\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m input_nikud \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([torch\u001b[39m.\u001b[39;49mfull((target_nikud_ids\u001b[39m.\u001b[39;49msize(\u001b[39m0\u001b[39;49m), \u001b[39m1\u001b[39;49m), no_nikud_id, dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlong), target_nikud_ids[:, :\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]], dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     58\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids, input_nikud)\n\u001b[0;32m     60\u001b[0m \u001b[39m# Reshape outputs and target_nikud_ids for loss computation\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
     ]
    }
   ],
   "source": [
    "\n",
    "class NikudPredictor(nn.Module):\n",
    "    def __init__(self, vocab_size, pad_idx_src, pad_idx_tgt, no_nikud_id, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout):\n",
    "        super(NikudPredictor, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.transformer = Transformer(d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        self.pad_idx_src = pad_idx_src\n",
    "        self.pad_idx_tgt = pad_idx_tgt\n",
    "        self.no_nikud_id = no_nikud_id\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.pad_idx_src).unsqueeze(-2)\n",
    "        return src_mask\n",
    "\n",
    "    def make_tgt_mask(self, tgt):\n",
    "        tgt_pad_mask = (tgt != self.pad_idx_tgt).unsqueeze(-2)\n",
    "        tgt_sub_mask = torch.triu(torch.ones((tgt.size(1), tgt.size(1))), diagonal=1)\n",
    "        tgt_mask = tgt_pad_mask & tgt_sub_mask\n",
    "        return tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        tgt_mask = self.make_tgt_mask(tgt)\n",
    "        \n",
    "        embedded_src = self.embedding(src)\n",
    "        embedded_tgt = self.embedding(tgt)\n",
    "        \n",
    "        transformer_out = self.transformer(embedded_src, embedded_tgt, src_mask, tgt_mask)\n",
    "        output = self.fc_out(transformer_out)\n",
    "        \n",
    "        return output\n",
    "\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "num_decoder_layers = 6\n",
    "dim_feedforward = 2048\n",
    "dropout = 0.1\n",
    "no_nikud_id = 0\n",
    "pad_idx_src = 0\n",
    "pad_idx_tgt = len(label_to_id)\n",
    "# Assuming you have a DataLoader named 'dataloader' that gives you batches of input_ids and target nikud_ids\n",
    "model = NikudPredictor(vocab_size, pad_idx_src, pad_idx_tgt, no_nikud_id, d_model, nhead, num_encoder_layers, num_decoder_layers, dim_feedforward, dropout)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx_tgt)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        target_nikud_ids = batch[\"nikud\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Shift the decoder tokens right (this is a common practice in transformer models)\n",
    "        input_nikud = torch.cat([torch.full((target_nikud_ids.size(0), 1), no_nikud_id, dtype=torch.long), target_nikud_ids[:, :-1]], dim=1)\n",
    "        \n",
    "        outputs = model(input_ids, input_nikud)\n",
    "        \n",
    "        # Reshape outputs and target_nikud_ids for loss computation\n",
    "        outputs = outputs.reshape(-1, outputs.shape[2])\n",
    "        target_nikud_ids = target_nikud_ids.reshape(-1)\n",
    "        \n",
    "        loss = criterion(outputs, target_nikud_ids)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
